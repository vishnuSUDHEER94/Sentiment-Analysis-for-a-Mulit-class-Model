{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeU-M31nhMKA",
        "colab_type": "code",
        "outputId": "33decc4d-87a3-4369-d9d5-21134aa8f8df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "# Import the pandas library to read our dataset \n",
        "import pandas as pd\n",
        "# Get the train/test split package from sklearn for preparing our dataset to # train and test the model with \n",
        "from sklearn.model_selection import train_test_split\n",
        "# Import the numpy library to work with and manipulate the data \n",
        "# Get the train/test split package from sklearn for preparing our dataset to\n",
        "# train and test the model with\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Import the numpy library to read our dataset \n",
        "import numpy as np\n",
        "# Import the seaborn library to read our dataset \n",
        "import seaborn as sns\n",
        "# Import the matplotlib library to read our dataset \n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(color_codes=True)\n",
        "# Import the nltk library to read our dataset \n",
        "import nltk \n",
        "# Import the random library to read our dataset \n",
        "import random \n",
        "from nltk.tokenize import word_tokenize\n",
        "# downloading the punkt\n",
        "nltk.download('punkt') \n",
        "# downloading the stopwords\n",
        "nltk.download('stopwords') \n",
        "# downloading the wordnet\n",
        "nltk.download('wordnet') "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQObS4LohrAi",
        "colab_type": "code",
        "outputId": "ce8248fe-258d-4275-a4f7-659640bd92dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Imported the necessary libraries\n",
        "import csv\n",
        "import urllib.request as urllib2\n",
        "# Importing the matplotlib library\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk import FreqDist\n",
        "# importing the pandas\n",
        "import pandas as pd\n",
        "# Importing data using url\n",
        "url = 'https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv'\n",
        "response = urllib2.urlopen(url)\n",
        "\n",
        "# reading data using pandas and converting into dataframe\n",
        "df = pd.read_csv(response,delimiter='\\t',encoding='utf-8')\n",
        "df.head()\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt7ozRPShuxe",
        "colab_type": "code",
        "outputId": "1ed99ea2-849a-49fd-b184-d740a54f44c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# resetting the index\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>51465</td>\n",
              "      <td>2534</td>\n",
              "      <td>this clever and very satisfying picture is mor...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>87992</td>\n",
              "      <td>4572</td>\n",
              "      <td>-LRB- Jeff 's -RRB- gorgeous , fluid compositi...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54192</td>\n",
              "      <td>2691</td>\n",
              "      <td>DV</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18057</td>\n",
              "      <td>787</td>\n",
              "      <td>would be a worthy substitute for naughty child...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>153391</td>\n",
              "      <td>8378</td>\n",
              "      <td>blasphemous bad</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0     51465  ...          3\n",
              "1     87992  ...          3\n",
              "2     54192  ...          2\n",
              "3     18057  ...          2\n",
              "4    153391  ...          0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX6PU2KdiHAK",
        "colab_type": "code",
        "outputId": "29a7b6f5-8039-4cdc-f384-3e5a67803780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# spliting the both train data and test data in the ratio of 70:30\n",
        "# setting the random_state to 2003\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df ['Phrase'], df ['Sentiment'], test_size=0.3, random_state=2003)\n",
        "documents=[]\n",
        "# converting both X_train and Y_train to numpy arrays\n",
        "X_train = np.array(X_train.values.tolist())\n",
        "Y_train = np.array(Y_train.values.tolist())\n",
        "\n",
        "# tokenizing and appending to the document\n",
        "for i in range(len(X_train)):\n",
        "  documents.append([list(word_tokenize(X_train[i])), Y_train[i]]) \n",
        "# converting both X_test and Y_test to numpy arrays\n",
        "X_test = np.array(X_test.values.tolist())\n",
        "Y_test = np.array(Y_test.values.tolist())\n",
        "for i in range(len(X_test)):\n",
        "  documents.append([list(word_tokenize(X_test[i])), Y_test[i]]) \n",
        "\n",
        "documents[0]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['possibly', 'the', 'best', 'actor', 'working', 'in', 'movies', 'today'], 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqLL8bD3iiTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer \n",
        "porter = PorterStemmer() \n",
        "lancaster=LancasterStemmer() \n",
        "wordnet_lemmatizer = WordNetLemmatizer() \n",
        "stopwords_en = stopwords.words(\"english\") \n",
        "punctuations=\"?:!.,;'\\\"-()\"\n",
        "#parameters to adjust to see the impact on outcome \n",
        "remove_stopwords = True\n",
        "useStemming = False\n",
        "useLemma = False\n",
        "removePuncs = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y82wuQmiioM0",
        "colab_type": "code",
        "outputId": "19c46ab4-c0fc-4f1a-8925-fe1ccc898e99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#For each and every review for the given document\n",
        "for l in range(len(documents)): \n",
        "  #Have to Save the label                   \n",
        "  label = documents[l][1]    \n",
        "  #A new list for new review                       \n",
        "  tmpReview = []\n",
        "  #For each and evry word in the review                                  \n",
        "  for w in documents[l][0]:  \n",
        "    #Setting the newWork for the updated word                      \n",
        "    newWord = w        \n",
        "    #if the given word is a stopword & we need to remove those stopwords                            \n",
        "    if remove_stopwords and (w in stopwords_en):  \n",
        "      #skip the word and don’t make in to the normalized review \n",
        "      continue  \n",
        "    #if the given word is a punc & we need to remove those punctuations                                   \n",
        "    if removePuncs and (w in punctuations): \n",
        "      #skip the word and don’t make in to the normalized review       \n",
        "      continue                                     \n",
        "    if useStemming:\n",
        "      #if useStemming is made to True \n",
        "      #Using the Lancaster stemmer\n",
        "      newWord = lancaster.stem(newWord)  \n",
        "    if useLemma: \n",
        "      newWord = wordnet_lemmatizer.lemmatize(newWord) \n",
        "    #Adding normalized word to the tmpReview\n",
        "    tmpReview.append(newWord)  \n",
        "  #Update the reviews list with clean review                    \n",
        "  documents[l] = (tmpReview, label)              \n",
        "  documents[l] = (' '.join(tmpReview), label) \n",
        "\n",
        "print(documents[0])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('possibly best actor working movies today', 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi3Xtcbyjhq_",
        "colab_type": "code",
        "outputId": "4f00c24d-84e5-4e80-a04f-c76d3a998317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.DataFrame(documents, columns=['text', 'sentiment']) \n",
        "df.head()\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>possibly best actor working movies today</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>n't much</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>evocative shades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>following</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       text  sentiment\n",
              "0  possibly best actor working movies today          4\n",
              "1                                                    2\n",
              "2                                  n't much          1\n",
              "3                          evocative shades          2\n",
              "4                                 following          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9RsYPHDjlbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spliting the both train data and test data in the ratio of 70:30\n",
        "# setting the random_state to 2003\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df['text'],  df['sentiment'], test_size=0.3, random_state=2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoEzDV3gjoLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing CountVectorizer, TfidVectorizer from sklearn.feature_extraction.text\n",
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features = 2000,ngram_range=(2, 2)) \n",
        "X = vectorizer.fit_transform(df[\"text\"]) \n",
        "Y = df['sentiment'] \n",
        " \n",
        "X_train = vectorizer.transform(X_train).toarray()\n",
        "Y_train = Y_train \n",
        "X_test = vectorizer.transform(X_test).toarray()\n",
        "Y_test = Y_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uIneGVNjtIp",
        "colab_type": "code",
        "outputId": "d312e17a-6437-4262-8cca-ccf207d2b668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13510     2\n",
              "61932     3\n",
              "82549     1\n",
              "137718    1\n",
              "121990    2\n",
              "         ..\n",
              "94224     2\n",
              "135456    2\n",
              "154729    4\n",
              "23031     2\n",
              "57870     4\n",
              "Name: sentiment, Length: 46818, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5I9RDj9jwcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flf290MljyPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculating the recall_m value with the true_positives and possible positives\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "#Calculating the precision_m value with the true_positives and predicted positives\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "#Calculating the f1_m value with the precision and recall\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbb0JDu3j141",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainable parameters\n",
        "batch_size = 64\n",
        "num_classes = 5\n",
        "epochs = 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcVW7hCej7c0",
        "colab_type": "code",
        "outputId": "1947ee5a-8080-4413-c858-b4389fead422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109242, 2000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-cycWStkAGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# performing categorical function\n",
        "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
        "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytnq211CkDkK",
        "colab_type": "code",
        "outputId": "b5121c9c-b39d-4d41-9ea0-699f25b36274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqw58ZuwkHzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, Embedding, Flatten\n",
        "from keras.layers import SpatialDropout1D\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.models import Sequential\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmqaivk5kMzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definning the model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3,\n",
        "                 activation='relu',\n",
        "                 input_shape=(2000,1)))\n",
        "model.add(Conv1D(128, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=1))\n",
        "model.add(Dropout(rate = 0.50))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ARY80xPkUGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy',f1_m,precision_m, recall_m])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpnOMeYLkgZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTFGf9pJknp7",
        "colab_type": "code",
        "outputId": "6adaaf6d-1fcd-499d-eb98-6ded5845b2b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=128,\n",
        "          epochs=10)\n",
        "# _, accuracy = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=0)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print('Test f1-score:', score[2])\n",
        "print('Test precision:', score[3])\n",
        "print('Test recall:', score[4])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "109242/109242 [==============================] - 87s 800us/step - loss: 1.2578 - acc: 0.5210 - f1_m: 0.3859 - precision_m: 0.5160 - recall_m: 0.3523\n",
            "Epoch 2/10\n",
            "109242/109242 [==============================] - 86s 790us/step - loss: 1.2104 - acc: 0.5370 - f1_m: 0.4963 - precision_m: 0.5557 - recall_m: 0.4605\n",
            "Epoch 3/10\n",
            "109242/109242 [==============================] - 86s 790us/step - loss: 1.1990 - acc: 0.5395 - f1_m: 0.5001 - precision_m: 0.5568 - recall_m: 0.4647\n",
            "Epoch 4/10\n",
            "109242/109242 [==============================] - 86s 788us/step - loss: 1.1932 - acc: 0.5404 - f1_m: 0.5123 - precision_m: 0.5576 - recall_m: 0.4789\n",
            "Epoch 5/10\n",
            "109242/109242 [==============================] - 86s 788us/step - loss: 1.1896 - acc: 0.5413 - f1_m: 0.5180 - precision_m: 0.5578 - recall_m: 0.4863\n",
            "Epoch 6/10\n",
            "109242/109242 [==============================] - 86s 788us/step - loss: 1.1877 - acc: 0.5417 - f1_m: 0.5198 - precision_m: 0.5584 - recall_m: 0.4885\n",
            "Epoch 7/10\n",
            "109242/109242 [==============================] - 86s 788us/step - loss: 1.1863 - acc: 0.5416 - f1_m: 0.5147 - precision_m: 0.5592 - recall_m: 0.4827\n",
            "Epoch 8/10\n",
            "109242/109242 [==============================] - 86s 789us/step - loss: 1.1863 - acc: 0.5425 - f1_m: 0.5121 - precision_m: 0.5603 - recall_m: 0.4794\n",
            "Epoch 9/10\n",
            "109242/109242 [==============================] - 86s 788us/step - loss: 1.1836 - acc: 0.5434 - f1_m: 0.5229 - precision_m: 0.5595 - recall_m: 0.4927\n",
            "Epoch 10/10\n",
            "109242/109242 [==============================] - 86s 788us/step - loss: 1.1821 - acc: 0.5440 - f1_m: 0.5223 - precision_m: 0.5605 - recall_m: 0.4913\n",
            "Test loss: 1.2215656575839255\n",
            "Test accuracy: 0.5329146909308385\n",
            "Test f1-score: 0.5187393197454562\n",
            "Test precision: 0.5501354790043508\n",
            "Test recall: 0.49160579264385496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OuqmqOVnp8P",
        "colab_type": "code",
        "outputId": "fa370020-478d-4acb-dd2a-6ce1ec2eb50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.save(\"1110200_1dconv_reg.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRIjLPM6ntDZ",
        "colab_type": "code",
        "outputId": "d988e5f4-21e6-45c6-c036-ce79521f0b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "\n",
        "# load and evaluate a saved model\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        " \n",
        "# load model\n",
        "#model = load_model('model.h5')\n",
        "model = load_model('1110200_1dconv_reg.h5', custom_objects={'f1_m': f1_m, 'precision_m':precision_m, 'recall_m':recall_m})\n",
        "# summarize model.\n",
        "model.summary()\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_5 (Conv1D)            (None, 1998, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 1994, 128)         41088     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 1994, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1994, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 255232)            0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 1276165   \n",
            "=================================================================\n",
            "Total params: 1,317,509\n",
            "Trainable params: 1,317,509\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}